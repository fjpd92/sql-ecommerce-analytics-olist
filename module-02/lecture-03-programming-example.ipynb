{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b44a91bd",
      "metadata": {
        "id": "b44a91bd"
      },
      "source": [
        "# Lecture 3: Programming Example - Pandas Fundamentals with Washington D.C. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f548ee",
      "metadata": {
        "id": "45f548ee"
      },
      "source": [
        "## Introduction: Your First Day as a Data Consultant\n",
        "\n",
        "Welcome to your first hands-on session as a junior data consultant! Today, you'll work with real Washington D.C. bike-sharing data, learning pandas step-by-step. We'll start with absolute basics and build up to loading and exploring your client's dataset.\n",
        "\n",
        "> **ðŸš€ Interactive Learning Alert**\n",
        ">\n",
        "> This is a hands-on programming tutorial with code examples and challenges. For the best learning experience:\n",
        ">\n",
        "> - **Click \"Open in Colab\"** at the bottom of this notebook to run it in Google Colab\n",
        "> - **Execute each code cell** by pressing **Shift + Enter** to see the results\n",
        "> - **Complete the challenges** to practice what you learn\n",
        ">\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb855692",
      "metadata": {
        "id": "bb855692"
      },
      "source": [
        "## Step 1: Setting Up Your Data Analysis Environment\n",
        "\n",
        "Let's start by importing the tools you'll need for data analysis. Think of this like setting up your workbench before starting a project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "724575f5",
      "metadata": {
        "id": "724575f5",
        "outputId": "515df416-bcc5-4e11-9880-398e50ebdca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas imported successfully!\n",
            "Pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Import pandas - your primary data manipulation tool\n",
        "import pandas as pd\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Pandas imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d103433",
      "metadata": {
        "id": "4d103433"
      },
      "source": [
        "> **Note:** To run a code cell in Jupyter Notebook, click inside the cell and press **Shift + Enter**. This will execute the code and show the output directly below the cell.\n",
        "\n",
        "**What this does:**\n",
        "- `import pandas as pd` makes the pandas library available with the shorthand \"pd\"\n",
        "- The shorthand `pd` is a universal convention - all pandas users worldwide use this\n",
        "- Checking the version ensures you're working with up-to-date tools. In real-world projects, you usually just import pandas and skip printing the version or confirmation messages. We're doing it here only for teaching purposes, so you can see exactly what's happening step by step.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d6d0507",
      "metadata": {
        "id": "9d6d0507"
      },
      "source": [
        "### Challenge 1: Import Practice\n",
        "Import pandas yourself, then check that it worked by running `type(pd)`. The output should be `<class 'module'>`, confirming that `pd` is a module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "a1ebeba4",
      "metadata": {
        "id": "a1ebeba4",
        "outputId": "4fa1e565-4088-4bb2-bc4c-c99c684933a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'module'>\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "import pandas as pd  # Fill in the library name\n",
        "print(type(pd))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c11ded",
      "metadata": {
        "id": "82c11ded"
      },
      "source": [
        "> **Note:** To solve the exercise, replace each `_____` with the correct value or code. After that, expand the Solution section to compare your answer with the correct one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a50df45a",
      "metadata": {
        "id": "a50df45a"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Your code here\n",
        "import pandas as pd  # Fill in the library name\n",
        "print(type(pd))\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9a02c9",
      "metadata": {
        "id": "4c9a02c9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53c9569",
      "metadata": {
        "id": "d53c9569"
      },
      "source": [
        "## Step 2: Understanding Series - Single Column Data\n",
        "\n",
        "Let's start with Series by creating bike rental data for a typical Monday morning. Think of Series as a single column from a spreadsheet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "62e84edd",
      "metadata": {
        "id": "62e84edd",
        "outputId": "c7ccb20d-814e-462a-ead4-882b301015f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morning Bike Rentals:\n",
            "0     15\n",
            "1     23\n",
            "2     45\n",
            "3     67\n",
            "4     89\n",
            "5    156\n",
            "6    234\n",
            "7    287\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Create a Series with hourly bike rentals\n",
        "morning_rentals = pd.Series([15, 23, 45, 67, 89, 156, 234, 287])\n",
        "print(\"Morning Bike Rentals:\")\n",
        "print(morning_rentals)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19b15f8c",
      "metadata": {
        "id": "19b15f8c"
      },
      "source": [
        "**What this does:**\n",
        "- `morning_rentals = pd.Series([...])` creates a pandas Series object and saves it in the variable `morning_rentals`\n",
        "- The numbers on the right column represent bike rentals for each hour\n",
        "- The numbers on the left column are index numbers that Pandas automatically assigns (0, 1, 2, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc1a5c8",
      "metadata": {
        "id": "9cc1a5c8"
      },
      "source": [
        "### Challenge 2: Create Your Own Series\n",
        "Create a Series representing temperature readings for the same morning hours. Use these temperatures: [6, 7, 8, 10, 12, 13, 14, 16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "7cab4a56",
      "metadata": {
        "id": "7cab4a56",
        "outputId": "6effbe81-2797-4ea8-c850-d81c6e1dc251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     6\n",
            "1     7\n",
            "2     8\n",
            "3    10\n",
            "4    12\n",
            "5    13\n",
            "6    14\n",
            "7    16\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Import pandas for Series creation\n",
        "import pandas as pd\n",
        "\n",
        "# Your code here - create a Series called 'morning_temps'\n",
        "morning_temps = pd.Series([6, 7, 8, 10, 12, 13, 14, 16])  # Fill in the temperature list\n",
        "print(morning_temps)  # Print your Series to verify it worked"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a957811",
      "metadata": {
        "id": "3a957811"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When creating Series objects, consider these best practices:\n",
        "- Use descriptive variable names like `morning_temps` instead of generic names like `data`\n",
        "- Print the Series to verify it contains the expected values and structure\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fb2852",
      "metadata": {
        "id": "54fb2852"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import pandas for Series creation\n",
        "import pandas as pd\n",
        "\n",
        "# Your code here - create a Series called 'morning_temps'\n",
        "morning_temps = pd.Series([6, 7, 8, 10, 12, 13, 14, 16])  # Fill in the temperature list\n",
        "print(morning_temps)  # Print your Series to verify it worked\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b03bafb",
      "metadata": {
        "id": "5b03bafb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2946ce18",
      "metadata": {
        "id": "2946ce18"
      },
      "source": [
        "## Step 3: Adding Meaningful Labels to Series\n",
        "\n",
        "Raw index numbers (0, 1, 2) aren't very business-friendly. Let's add meaningful labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "dd1309c5",
      "metadata": {
        "id": "dd1309c5",
        "outputId": "07389b13-e2cb-4455-f9c5-df9d80a3e957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled Morning Bike Rentals:\n",
            "6 AM      15\n",
            "7 AM      23\n",
            "8 AM      45\n",
            "9 AM      67\n",
            "10 AM     89\n",
            "11 AM    156\n",
            "12 PM    234\n",
            "1 PM     287\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Create Series with meaningful hour labels\n",
        "hour_labels = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM', '12 PM', '1 PM']\n",
        "morning_rentals_labeled = pd.Series([15, 23, 45, 67, 89, 156, 234, 287],\n",
        "                                   index=hour_labels)\n",
        "print(\"Labeled Morning Bike Rentals:\")\n",
        "print(morning_rentals_labeled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25937ff",
      "metadata": {
        "id": "e25937ff"
      },
      "source": [
        "**What this does:**\n",
        "- `hour_labels = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM', '12 PM', '1 PM']` creates a list of time labels that represent each hour in the morning\n",
        "- `index=hour_labels` replaces default numbers with business-meaningful labels created in the previous line\n",
        "- Now each rental count is clearly connected to its time period\n",
        "\n",
        "Now when you show this to your client, they immediately understand that 1 PM has the highest rentals (287), which makes perfect sense for lunch-time bike usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc65093",
      "metadata": {
        "id": "bcc65093"
      },
      "source": [
        "### Challenge 3: Access Specific Data Points\n",
        "Using your labeled Series, find the bike rentals at 9 AM. Use this syntax: `morning_rentals_labeled['9 AM']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f1ca6f35",
      "metadata": {
        "id": "f1ca6f35",
        "outputId": "745e4297-06ae-4434-87a6-0175edaf0126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bike rentals at 9 AM: 67\n"
          ]
        }
      ],
      "source": [
        "# Import pandas and create the labeled Series\n",
        "import pandas as pd\n",
        "\n",
        "# Create Series with meaningful hour labels\n",
        "hour_labels = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM', '12 PM', '1 PM']\n",
        "morning_rentals_labeled = pd.Series([15, 23, 45, 67, 89, 156, 234, 287],\n",
        "                                   index=hour_labels)\n",
        "\n",
        "# Your code here - access the 9 AM value from the labeled Series\n",
        "nine_am_rentals = morning_rentals_labeled['9 AM']  # Fill in the correct label\n",
        "print(f\"Bike rentals at 9 AM: {nine_am_rentals }\")  # Print the result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc499ec",
      "metadata": {
        "id": "7bc499ec"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When accessing Series data by label, keep these techniques in mind:\n",
        "- In this challenge, we're using square brackets with the exact label: `series_name['label']`\n",
        "- Check available labels with `series_name.index` to see all options\n",
        "- Access multiple values: `series_name[['9 AM', '10 AM']]` (note double brackets)\n",
        "- Use `.loc[]` for explicit label-based selection: `series_name.loc['9 AM']`\n",
        "- Be careful with exact spelling and spacing in labels to avoid KeyError\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072b27b1",
      "metadata": {
        "id": "072b27b1"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import pandas and create the labeled Series\n",
        "import pandas as pd\n",
        "\n",
        "# Create Series with meaningful hour labels\n",
        "hour_labels = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM', '12 PM', '1 PM']\n",
        "morning_rentals_labeled = pd.Series([15, 23, 45, 67, 89, 156, 234, 287],\n",
        "                                   index=hour_labels)\n",
        "\n",
        "# Your code here - access the 9 AM value from the labeled Series\n",
        "nine_am_rentals = morning_rentals_labeled['9 AM']  # Fill in the correct label\n",
        "print(f\"Bike rentals at 9 AM: {nine_am_rentals}\")  # Print the result\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5350f229",
      "metadata": {
        "id": "5350f229"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973eeda3",
      "metadata": {
        "id": "973eeda3"
      },
      "source": [
        "## Step 4: Creating Your First DataFrame - Complete Business Data\n",
        "\n",
        "Now let's combine multiple pieces of information into a DataFrame. Think of this as creating a complete spreadsheet with multiple columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "fa6311cd",
      "metadata": {
        "id": "fa6311cd",
        "outputId": "e003b3d9-6487-4bc8-b2bf-b9653252ae36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete Bike Operations Data:\n",
            "    hour  temperature  bike_rentals weather_condition\n",
            "0   6 AM          5.6            15             Clear\n",
            "1   7 AM          6.7            23             Clear\n",
            "2   8 AM          8.3            45     Partly Cloudy\n",
            "3   9 AM         10.0            67             Clear\n",
            "4  10 AM         11.7            89             Clear\n"
          ]
        }
      ],
      "source": [
        "# Create a comprehensive DataFrame with multiple variables\n",
        "bike_operations_data = pd.DataFrame({\n",
        "    'hour': ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM'],\n",
        "    'temperature': [5.6, 6.7, 8.3, 10.0, 11.7],\n",
        "    'bike_rentals': [15, 23, 45, 67, 89],\n",
        "    'weather_condition': ['Clear', 'Clear', 'Partly Cloudy', 'Clear', 'Clear']\n",
        "})\n",
        "\n",
        "print(\"Complete Bike Operations Data:\")\n",
        "print(bike_operations_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d91d31",
      "metadata": {
        "id": "96d91d31"
      },
      "source": [
        "**What this does:**\n",
        "- `pd.DataFrame({...})` creates a DataFrame with multiple columns\n",
        "- The DataFrame constructor accepts a dictionary where:\n",
        "  - each key (like 'hour', 'temperature', etc.) becomes a column name\n",
        "  - each list in the dictionary provides the values for that column\n",
        "- All rows stay aligned (first hour corresponds to first temperature, etc.)\n",
        "\n",
        "You can immediately see patterns - bike rentals increase with temperature and time, giving your client valuable operational insights.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8dad344",
      "metadata": {
        "id": "d8dad344"
      },
      "source": [
        "### Challenge 4: Add a New Column\n",
        "Add a column called 'user_satisfaction' with values [3.2, 3.5, 3.8, 4.1, 4.3] representing customer satisfaction ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "59804935",
      "metadata": {
        "id": "59804935",
        "outputId": "ffef44fc-3b5c-4061-8196-34bfea8aeeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    hour  temperature  bike_rentals weather_condition  user_satisfaction\n",
            "0   6 AM          5.6            15             Clear                3.2\n",
            "1   7 AM          6.7            23             Clear                3.5\n",
            "2   8 AM          8.3            45     Partly Cloudy                3.8\n",
            "3   9 AM         10.0            67             Clear                4.1\n",
            "4  10 AM         11.7            89             Clear                4.3\n",
            "hour                  object\n",
            "temperature          float64\n",
            "bike_rentals           int64\n",
            "weather_condition     object\n",
            "user_satisfaction    float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Import pandas and create the DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Create a comprehensive DataFrame with multiple variables\n",
        "bike_operations_data = pd.DataFrame({\n",
        "    'hour': ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM'],\n",
        "    'temperature': [5.6, 6.7, 8.3, 10.0, 11.7],\n",
        "    'bike_rentals': [15, 23, 45, 67, 89],\n",
        "    'weather_condition': ['Clear', 'Clear', 'Partly Cloudy', 'Clear', 'Clear']\n",
        "})\n",
        "\n",
        "# Your code here - add a new column with satisfaction ratings\n",
        "bike_operations_data['user_satisfaction'] = [3.2, 3.5, 3.8, 4.1, 4.3]  # Fill in column name\n",
        "print(bike_operations_data)  # Print the updated DataFrame\n",
        "print(bike_operations_data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2ebe7da",
      "metadata": {
        "id": "c2ebe7da"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When adding new columns to DataFrames, follow these best practices:\n",
        "- Ensure the new data list has the same length as existing rows: `len(new_data) == len(df)`\n",
        "- Use descriptive column names that clearly indicate what the data represents\n",
        "- Verify the addition worked: `df.columns` shows all column names including the new one\n",
        "- Check data types: `df.dtypes` to ensure the new column has appropriate type (float64 for ratings)\n",
        "- You can also add columns using `df.assign(column_name=values)` for a more functional approach\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc3e7fa",
      "metadata": {
        "id": "dbc3e7fa"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import pandas and create the DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Create a comprehensive DataFrame with multiple variables\n",
        "bike_operations_data = pd.DataFrame({\n",
        "    'hour': ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM'],\n",
        "    'temperature': [5.6, 6.7, 8.3, 10.0, 11.7],\n",
        "    'bike_rentals': [15, 23, 45, 67, 89],\n",
        "    'weather_condition': ['Clear', 'Clear', 'Partly Cloudy', 'Clear', 'Clear']\n",
        "})\n",
        "\n",
        "# Your code here - add a new column with satisfaction ratings\n",
        "bike_operations_data['user_satisfaction'] = [3.2, 3.5, 3.8, 4.1, 4.3]  # Fill in column name\n",
        "print(bike_operations_data)  # Print the updated DataFrame\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd14fa2d",
      "metadata": {
        "id": "fd14fa2d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077ba4a5",
      "metadata": {
        "id": "077ba4a5"
      },
      "source": [
        "## Step 5: Loading Real Washington D.C. Dataset\n",
        "\n",
        "Now for the real challenge - loading your client's actual historical data. This is where professional consulting begins:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "7369720b",
      "metadata": {
        "id": "7369720b",
        "outputId": "20b2fe31-181c-44af-b3db-131d8459db2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Shape: 10886 rows Ã— 12 columns\n"
          ]
        }
      ],
      "source": [
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Confirm successful loading\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d18a0d1",
      "metadata": {
        "id": "7d18a0d1"
      },
      "source": [
        "**What this does:**\n",
        "- `pd.read_csv()` reads data from a CSV file into a DataFrame\n",
        "- CSV (Comma-Separated Values) a standard format for sharing tabular data\n",
        "- The shape tells you how much data you have to work with\n",
        "\n",
        "Always check the shape immediately after loading - it confirms the file loaded correctly and gives you a sense of your dataset size."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1888f9d7",
      "metadata": {
        "id": "1888f9d7"
      },
      "source": [
        "### Challenge 5: Explore the Column Names\n",
        "Print the column names using `df.columns` to see what variables are available in your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a3248577",
      "metadata": {
        "id": "a3248577",
        "outputId": "30de7393-327b-4932-c7dc-5e9bc4bbd4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns:\n",
            "['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - explore the available columns\n",
        "print(\"Available columns:\")\n",
        "print(list(df.columns))  # Fill in the DataFrame name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69f40fc",
      "metadata": {
        "id": "c69f40fc"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When exploring column names in a new dataset, use these investigation techniques:\n",
        "- `df.columns` returns an Index object with all column names\n",
        "- `list(df.columns)` converts to a regular Python list for easier reading\n",
        "- `len(df.columns)` tells you how many variables you have to work with\n",
        "- Look for patterns in naming conventions to understand data structure\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560caf59",
      "metadata": {
        "id": "560caf59"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - explore the available columns\n",
        "print(\"Available columns:\")\n",
        "print(list(df.columns))  # Fill in the DataFrame name\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a6d610",
      "metadata": {
        "id": "a8a6d610"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4eaeed6",
      "metadata": {
        "id": "c4eaeed6"
      },
      "source": [
        "## Step 6: First Look at Real Transportation Data\n",
        "\n",
        "Let's examine the first few rows to understand the data structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "f1d326cb",
      "metadata": {
        "id": "f1d326cb",
        "outputId": "ef0c4ab4-d633-4c0b-b769-7f9f049c92d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
            "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
            "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
            "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
            "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
            "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
            "\n",
            "   humidity  windspeed  casual  registered  count  \n",
            "0        81        0.0       3          13     16  \n",
            "1        80        0.0       8          32     40  \n",
            "2        80        0.0       5          27     32  \n",
            "3        75        0.0       3          10     13  \n",
            "4        75        0.0       0           1      1  \n"
          ]
        }
      ],
      "source": [
        "# Display the first 5 rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff60c17c",
      "metadata": {
        "id": "ff60c17c"
      },
      "source": [
        "**What this shows:**\n",
        "- `head()` displays the first 5 rows by default (you can specify a different number like `df.head(10)` to see 10 rows)\n",
        "- You'll see actual bike-sharing data with timestamps, weather, and usage counts\n",
        "- Each row represents one hour of bike-sharing operations\n",
        "\n",
        "**Understanding the real data:**\n",
        "- `datetime`: When this data was recorded\n",
        "- `season`, `holiday`, `workingday`: Operational context\n",
        "- `weather`, `temp`, `humidity`, `windspeed`: Weather conditions\n",
        "- `casual`, `registered`, `count`: Different types of users and total rentals\n",
        "\n",
        "This is the foundation of all your future analysis for this client."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f531c58",
      "metadata": {
        "id": "4f531c58"
      },
      "source": [
        "### Challenge 6: Look at the Last Few Rows\n",
        "Use `df.tail()` to see the last 5 rows of the dataset. This helps verify you have complete data coverage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "eb8517d4",
      "metadata": {
        "id": "eb8517d4",
        "outputId": "9083d44d-6da3-4580-aefa-6dc504f1d1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 5 rows of the dataset:\n",
            "<bound method NDFrame.tail of                   datetime  season  holiday  workingday  weather   temp  \\\n",
            "0      2011-01-01 00:00:00       1        0           0        1   9.84   \n",
            "1      2011-01-01 01:00:00       1        0           0        1   9.02   \n",
            "2      2011-01-01 02:00:00       1        0           0        1   9.02   \n",
            "3      2011-01-01 03:00:00       1        0           0        1   9.84   \n",
            "4      2011-01-01 04:00:00       1        0           0        1   9.84   \n",
            "...                    ...     ...      ...         ...      ...    ...   \n",
            "10881  2012-12-19 19:00:00       4        0           1        1  15.58   \n",
            "10882  2012-12-19 20:00:00       4        0           1        1  14.76   \n",
            "10883  2012-12-19 21:00:00       4        0           1        1  13.94   \n",
            "10884  2012-12-19 22:00:00       4        0           1        1  13.94   \n",
            "10885  2012-12-19 23:00:00       4        0           1        1  13.12   \n",
            "\n",
            "        atemp  humidity  windspeed  casual  registered  count  \n",
            "0      14.395        81     0.0000       3          13     16  \n",
            "1      13.635        80     0.0000       8          32     40  \n",
            "2      13.635        80     0.0000       5          27     32  \n",
            "3      14.395        75     0.0000       3          10     13  \n",
            "4      14.395        75     0.0000       0           1      1  \n",
            "...       ...       ...        ...     ...         ...    ...  \n",
            "10881  19.695        50    26.0027       7         329    336  \n",
            "10882  17.425        57    15.0013      10         231    241  \n",
            "10883  15.910        61    15.0013       4         164    168  \n",
            "10884  17.425        61     6.0032      12         117    129  \n",
            "10885  16.665        66     8.9981       4          84     88  \n",
            "\n",
            "[10886 rows x 12 columns]>\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - examine the last few rows\n",
        "print(\"Last 5 rows of the dataset:\")\n",
        "print(df.tail)  # Fill in the DataFrame name and method"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12386e6",
      "metadata": {
        "id": "e12386e6"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When examining the end of your dataset, consider these data quality checks:\n",
        "- Compare last row's datetime to first row's datetime to understand time coverage\n",
        "- Check if the last rows have complete data or if there are missing values\n",
        "- Use `df.tail(10)` to see more rows if you want a larger sample\n",
        "- Look for any unusual patterns or data entry errors in the final records\n",
        "- Verify that the data collection didn't stop abruptly mid-period\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99bb2a56",
      "metadata": {
        "id": "99bb2a56"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - examine the last few rows\n",
        "print(\"Last 5 rows of the dataset:\")\n",
        "print(df.tail())  # Fill in the DataFrame name and method\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f6ee3d",
      "metadata": {
        "id": "a6f6ee3d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5dde8f",
      "metadata": {
        "id": "8e5dde8f"
      },
      "source": [
        "## Step 7: Understanding Your Dataset Size and Structure\n",
        "\n",
        "Professional data analysis requires understanding exactly what you're working with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "76aa61be",
      "metadata": {
        "id": "76aa61be",
        "outputId": "65b98bcf-fd1a-484f-9da2-7871dedddb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "Total records: 10886\n",
            "Total variables: 12\n",
            "\n",
            "Data Types:\n",
            "datetime       object\n",
            "season          int64\n",
            "holiday         int64\n",
            "workingday      int64\n",
            "weather         int64\n",
            "temp          float64\n",
            "atemp         float64\n",
            "humidity        int64\n",
            "windspeed     float64\n",
            "casual          int64\n",
            "registered      int64\n",
            "count           int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Get detailed information about the dataset\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Total records: {len(df)}\")\n",
        "print(f\"Total variables: {len(df.columns)}\")\n",
        "\n",
        "# Show data types for each column\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "341ed2a9",
      "metadata": {
        "id": "341ed2a9"
      },
      "source": [
        "**What this tells you:**\n",
        "- **Total records**: How much historical data your client has collected\n",
        "- **Total variables**: How many different factors you can analyze\n",
        "- **Data types**: What kind of analysis you can perform on each variable\n",
        "\n",
        "More historical data means more reliable predictions. The variety of variables (weather, time, user types) means you can build sophisticated demand forecasting models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a84ddd8a",
      "metadata": {
        "id": "a84ddd8a"
      },
      "source": [
        "### Challenge 7: Calculate Time Coverage\n",
        "The dataset contains hourly data. Calculate how many days of data you have by dividing the total rows by 24."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "4a872b12",
      "metadata": {
        "id": "4a872b12",
        "outputId": "b7318dde-7b9a-41e8-dfc4-231070e5f6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset covers approximately 453.6 days\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - calculate days of coverage\n",
        "total_days = len(df) / 24 # Fill in DataFrame name and divisor\n",
        "print(f\"Dataset covers approximately {total_days:.1f} days\")  # Fill in variable name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7a5917",
      "metadata": {
        "id": "ab7a5917"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When calculating time coverage for time series data, consider these analysis approaches:\n",
        "- Use `:.1f` formatting to display days with one decimal place for readability\n",
        "- Calculate weeks as well: `total_days / 7` for business planning context\n",
        "- Consider if you have complete days: `len(df) % 24` shows any partial days\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a3271e",
      "metadata": {
        "id": "87a3271e"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - calculate days of coverage\n",
        "total_days = len(df) / 24  # Fill in DataFrame name and divisor\n",
        "print(f\"Dataset covers approximately {total_days:.1f} days\")  # Fill in variable name\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b32e30",
      "metadata": {
        "id": "64b32e30"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34936b9d",
      "metadata": {
        "id": "34936b9d"
      },
      "source": [
        "## Step 8: Basic Statistical Summary\n",
        "\n",
        "Understanding the data distribution helps identify patterns and potential issues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "91656333",
      "metadata": {
        "id": "91656333",
        "outputId": "97e3466d-a539-4288-a1b8-e70de0c9b0a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Summary:\n",
            "             season       holiday    workingday       weather         temp  \\\n",
            "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
            "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
            "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
            "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
            "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
            "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
            "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
            "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
            "\n",
            "              atemp      humidity     windspeed        casual    registered  \\\n",
            "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
            "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
            "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
            "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
            "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
            "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
            "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
            "\n",
            "              count  \n",
            "count  10886.000000  \n",
            "mean     191.574132  \n",
            "std      181.144454  \n",
            "min        1.000000  \n",
            "25%       42.000000  \n",
            "50%      145.000000  \n",
            "75%      284.000000  \n",
            "max      977.000000  \n"
          ]
        }
      ],
      "source": [
        "# Generate statistical summary for numerical variables\n",
        "print(\"Statistical Summary:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c924bf",
      "metadata": {
        "id": "f0c924bf"
      },
      "source": [
        "**What this shows:**\n",
        "- **count**: How many non-missing values exist for each variable\n",
        "- **mean**: Average values (useful for understanding typical conditions)\n",
        "- **std**: Standard deviation (shows how much values vary)\n",
        "- **min/max**: Range of values (helps identify outliers or impossible values)\n",
        "- **25%, 50%, 75%**: Quartiles (show data distribution)\n",
        "\n",
        "If minimum bike counts are 1 and maximum is 977, that's a huge range! This suggests your client experiences very different demand conditions that you'll need to understand and predict."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be256ad",
      "metadata": {
        "id": "0be256ad"
      },
      "source": [
        "### Challenge 8: Focus on Key Business Metrics\n",
        "Create a summary focusing only on the key business variables: temperature (`temp`), humidity (`humidity`), and bike count (`count`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "5cafeb4c",
      "metadata": {
        "id": "5cafeb4c",
        "outputId": "f886e6b5-bb39-4817-879b-b43863cd1230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Business Metrics Summary:\n",
            "              temp      humidity         count\n",
            "count  10886.00000  10886.000000  10886.000000\n",
            "mean      20.23086     61.886460    191.574132\n",
            "std        7.79159     19.245033    181.144454\n",
            "min        0.82000      0.000000      1.000000\n",
            "25%       13.94000     47.000000     42.000000\n",
            "50%       20.50000     62.000000    145.000000\n",
            "75%       26.24000     77.000000    284.000000\n",
            "max       41.00000    100.000000    977.000000\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - create a summary of key metrics\n",
        "key_metrics = df[[\"temp\", \"humidity\", \"count\"]].describe()  # Fill in DataFrame and column names\n",
        "print(\"Key Business Metrics Summary:\")\n",
        "print(key_metrics)  # Print the summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2a30a0",
      "metadata": {
        "id": "7b2a30a0"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When focusing on specific business metrics, use these analytical techniques:\n",
        "- Select columns using double brackets: `df[['col1', 'col2']]` to maintain DataFrame structure\n",
        "- Compare ranges across variables to understand which have more variation\n",
        "- Check for outliers: are max values realistic or potentially data entry errors?\n",
        "- Consider business thresholds: what temperature ranges are most relevant for operations?\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46984b09",
      "metadata": {
        "id": "46984b09"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - create a summary of key metrics\n",
        "key_metrics = df[['temp', 'humidity', 'count']].describe()  # Fill in DataFrame and column names\n",
        "print(\"Key Business Metrics Summary:\")\n",
        "print(key_metrics)  # Print the summary\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c4e41f",
      "metadata": {
        "id": "40c4e41f"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad2e03c",
      "metadata": {
        "id": "bad2e03c"
      },
      "source": [
        "## Step 9: Selecting Specific Data for Analysis\n",
        "\n",
        "Often you need to focus on specific parts of your dataset. Let's learn several ways to select data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "af12b3b2",
      "metadata": {
        "id": "af12b3b2",
        "outputId": "4b7ce385-da14-4fb8-fe72-6b32e29a7bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bike counts - Type: <class 'pandas.core.series.Series'>\n",
            "Average daily rentals: 191.6\n",
            "\n",
            "Weather data shape: (10886, 3)\n",
            "   temp  humidity  windspeed\n",
            "0  9.84        81        0.0\n",
            "1  9.02        80        0.0\n",
            "2  9.02        80        0.0\n",
            "\n",
            "Sample data covers first 12 hours\n",
            "               datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
            "0   2011-01-01 00:00:00       1        0           0        1   9.84  14.395   \n",
            "1   2011-01-01 01:00:00       1        0           0        1   9.02  13.635   \n",
            "2   2011-01-01 02:00:00       1        0           0        1   9.02  13.635   \n",
            "3   2011-01-01 03:00:00       1        0           0        1   9.84  14.395   \n",
            "4   2011-01-01 04:00:00       1        0           0        1   9.84  14.395   \n",
            "5   2011-01-01 05:00:00       1        0           0        2   9.84  12.880   \n",
            "6   2011-01-01 06:00:00       1        0           0        1   9.02  13.635   \n",
            "7   2011-01-01 07:00:00       1        0           0        1   8.20  12.880   \n",
            "8   2011-01-01 08:00:00       1        0           0        1   9.84  14.395   \n",
            "9   2011-01-01 09:00:00       1        0           0        1  13.12  17.425   \n",
            "10  2011-01-01 10:00:00       1        0           0        1  15.58  19.695   \n",
            "11  2011-01-01 11:00:00       1        0           0        1  14.76  16.665   \n",
            "\n",
            "    humidity  windspeed  casual  registered  count  \n",
            "0         81     0.0000       3          13     16  \n",
            "1         80     0.0000       8          32     40  \n",
            "2         80     0.0000       5          27     32  \n",
            "3         75     0.0000       3          10     13  \n",
            "4         75     0.0000       0           1      1  \n",
            "5         75     6.0032       0           1      1  \n",
            "6         80     0.0000       2           0      2  \n",
            "7         86     0.0000       1           2      3  \n",
            "8         75     0.0000       1           7      8  \n",
            "9         76     0.0000       8           6     14  \n",
            "10        76    16.9979      12          24     36  \n",
            "11        81    19.0012      26          30     56  \n"
          ]
        }
      ],
      "source": [
        "# Select a single column (bike counts)\n",
        "bike_counts = df['count']\n",
        "print(f\"Bike counts - Type: {type(bike_counts)}\")\n",
        "print(f\"Average daily rentals: {bike_counts.mean():.1f}\")\n",
        "\n",
        "# Select multiple columns for weather analysis\n",
        "weather_data = df[['temp', 'humidity', 'windspeed']]\n",
        "print(f\"\\nWeather data shape: {weather_data.shape}\")\n",
        "print(weather_data.head(3))\n",
        "\n",
        "# Select first 12 rows for initial analysis\n",
        "sample_data = df.head(12)\n",
        "print(f\"\\nSample data covers first {len(sample_data)} hours\")\n",
        "print(sample_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2de8b55",
      "metadata": {
        "id": "a2de8b55"
      },
      "source": [
        "**What this demonstrates:**\n",
        "- **Single column selection**: Returns a Series (one-dimensional)\n",
        "- **Multiple column selection**: Returns a DataFrame (two-dimensional)\n",
        "- **Row selection**: Gets a subset of the full dataset\n",
        "\n",
        "You might analyze just weather data to understand seasonal patterns, or focus on the first few months to understand how the bike-sharing system performed during its early operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b886a555",
      "metadata": {
        "id": "b886a555"
      },
      "source": [
        "### Challenge 9: Create a Sample Dataset\n",
        "Select only the columns 'datetime', 'temp', 'count' and only the first 168 rows (first week of data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "28c67d26",
      "metadata": {
        "id": "28c67d26",
        "outputId": "f88411b9-ecef-470d-b302-f1eefb46011b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rush hour dataset shape: (168, 3)\n",
            "                datetime  temp  count\n",
            "0    2011-01-01 00:00:00  9.84     16\n",
            "1    2011-01-01 01:00:00  9.02     40\n",
            "2    2011-01-01 02:00:00  9.02     32\n",
            "3    2011-01-01 03:00:00  9.84     13\n",
            "4    2011-01-01 04:00:00  9.84      1\n",
            "..                   ...   ...    ...\n",
            "163  2011-01-08 02:00:00  7.38     16\n",
            "164  2011-01-08 03:00:00  7.38      7\n",
            "165  2011-01-08 04:00:00  7.38      1\n",
            "166  2011-01-08 05:00:00  6.56      5\n",
            "167  2011-01-08 06:00:00  6.56      2\n",
            "\n",
            "[168 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - create a focused dataset for rush hour analysis\n",
        "rush_hour_analysis = df[[ 'datetime', 'temp', 'count']].head(168)  # Fill in details\n",
        "print(f\"Rush hour dataset shape: {rush_hour_analysis.shape}\")  # Fill in variable name\n",
        "print(rush_hour_analysis)  # Print sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb89473b",
      "metadata": {
        "id": "eb89473b"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When creating focused analysis datasets, use these selection strategies:\n",
        "- Verify the subset size: 168 hours = 7 days Ã— 24 hours = 1 week\n",
        "- Combine column and row selection: `df[['col1', 'col2']].head(n)`\n",
        "- Confirm time coverage: compare first and last datetime values - as you will see, it doesn't match (this may mean that some hour registers are missing)\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d7712e",
      "metadata": {
        "id": "46d7712e"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - create a focused dataset for rush hour analysis\n",
        "rush_hour_analysis = df[['datetime', 'temp', 'count']].head(168)  # Fill in details\n",
        "print(f\"Rush hour dataset shape: {rush_hour_analysis.shape}\")  # Fill in variable name\n",
        "print(rush_hour_analysis)  # Print sample data\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffeee0a4",
      "metadata": {
        "id": "ffeee0a4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d1c5ad",
      "metadata": {
        "id": "82d1c5ad"
      },
      "source": [
        "## Step 10: Understanding Time-Based Data\n",
        "\n",
        "Transportation data is inherently time-based. Let's work with the datetime information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "715a8a03",
      "metadata": {
        "id": "715a8a03",
        "outputId": "ecf5a7a4-bc21-47df-d160-423b533170a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datetime conversion successful. Type: datetime64[ns]\n",
            "\n",
            "Data with extracted time components:\n",
            "             datetime  hour day_of_week  month  count\n",
            "0 2011-01-01 00:00:00     0    Saturday      1     16\n",
            "1 2011-01-01 01:00:00     1    Saturday      1     40\n",
            "2 2011-01-01 02:00:00     2    Saturday      1     32\n",
            "3 2011-01-01 03:00:00     3    Saturday      1     13\n",
            "4 2011-01-01 04:00:00     4    Saturday      1      1\n"
          ]
        }
      ],
      "source": [
        "# Convert datetime column to pandas datetime format\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "print(f\"Datetime conversion successful. Type: {df['datetime'].dtype}\")\n",
        "\n",
        "# Ensure chronological order for time-based operations\n",
        "df = df.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "# Extract useful time components\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "# Show the first few rows with time components\n",
        "print(\"\\nData with extracted time components:\")\n",
        "print(df[['datetime', 'hour', 'day_of_week', 'month', 'count']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bffaca22",
      "metadata": {
        "id": "bffaca22"
      },
      "source": [
        "> Timedelta primer: A Timedelta represents a duration (difference between two timestamps). You'll use `pd.Timedelta(hours=1)` in the next step to flag gaps larger than one hour between records.\n",
        "\n",
        "**What this accomplishes:**\n",
        "- Converts text dates to actual datetime objects for analysis\n",
        "- Extracts hour, day, and month for business analysis\n",
        "- Enables time-based filtering and grouping\n",
        "\n",
        "These **time-based features** unlock powerful insights. **Hour analysis** allows you to identify peak usage times for bike rebalancing, while **day analysis** helps compare weekday vs. weekend patterns. Additionally, **month analysis** reveals seasonal trends that are crucial for capacity planning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd14280",
      "metadata": {
        "id": "4bd14280"
      },
      "source": [
        "### Challenge 10: Find Peak Hour\n",
        "Use the new `hour` column to find which hour of the day has the highest average bike rentals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "8ff7bc2c",
      "metadata": {
        "id": "8ff7bc2c",
        "outputId": "6c017076-e611-46c6-c22b-dec59856f28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peak hour: 17:00\n",
            "Average rentals during peak hour: 468.8\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Convert datetime column and extract time components\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "# Your code here - find the peak hour for bike rentals\n",
        "hourly_average = df.groupby('hour')['count'].mean()  # Fill in DataFrame, grouping column, target column\n",
        "peak_hour = hourly_average.idxmax() # Fill in method to find maximum index\n",
        "peak_rentals = hourly_average.max()    # Fill in method to get maximum value\n",
        "\n",
        "print(f\"Peak hour: {peak_hour}:00\")  # Fill in variable name\n",
        "print(f\"Average rentals during peak hour: {peak_rentals:.1f}\")  # Fill in variable name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af77382",
      "metadata": {
        "id": "4af77382"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When analyzing time-based patterns, use these grouping and aggregation techniques:\n",
        "- `df.groupby('hour')['count'].mean()` calculates average by hour\n",
        "- Use `.idxmax()` to find the index (hour) with maximum value\n",
        "- Use `.max()` to get the actual maximum value\n",
        "- Explore other time patterns: `df.groupby('day_of_week')['count'].mean()`\n",
        "- Consider multiple aggregations: `df.groupby('hour')['count'].agg(['mean', 'std', 'count'])`\n",
        "- Sort results for easier interpretation: `hourly_average.sort_values(ascending=False)`\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d368396",
      "metadata": {
        "id": "8d368396"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Convert datetime column and extract time components\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "# Your code here - find the peak hour for bike rentals\n",
        "hourly_average = df.groupby('hour')['count'].mean()  # Fill in DataFrame, grouping column, target column\n",
        "peak_hour = hourly_average.idxmax()  # Fill in method to find maximum index\n",
        "peak_rentals = hourly_average.max()  # Fill in method to get maximum value\n",
        "\n",
        "print(f\"Peak hour: {peak_hour}:00\")  # Fill in variable name\n",
        "print(f\"Average rentals during peak hour: {peak_rentals:.1f}\")  # Fill in variable name\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1961a33",
      "metadata": {
        "id": "d1961a33"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571a37b4",
      "metadata": {
        "id": "571a37b4"
      },
      "source": [
        "## Step 11: Data Quality Assessment - Missing Data Detection (Empty Cells)\n",
        "\n",
        "Real-world data often has missing values (empty cells). Let's check if any values are missing from our dataset. Note that we're checking for empty cells here - detecting missing time periods (like skipped hours) requires a different approach that we'll handle in Challenge 11."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "37b7b1db",
      "metadata": {
        "id": "37b7b1db",
        "outputId": "e20fbe36-26ab-42b9-ca8d-faadc4821073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Data Summary:\n",
            "datetime       0\n",
            "season         0\n",
            "holiday        0\n",
            "workingday     0\n",
            "weather        0\n",
            "temp           0\n",
            "atemp          0\n",
            "humidity       0\n",
            "windspeed      0\n",
            "casual         0\n",
            "registered     0\n",
            "count          0\n",
            "hour           0\n",
            "day_of_week    0\n",
            "month          0\n",
            "dtype: int64\n",
            "\n",
            "Missing Data Percentages:\n",
            "datetime: 0% (Complete)\n",
            "season: 0% (Complete)\n",
            "holiday: 0% (Complete)\n",
            "workingday: 0% (Complete)\n",
            "weather: 0% (Complete)\n",
            "temp: 0% (Complete)\n",
            "atemp: 0% (Complete)\n",
            "humidity: 0% (Complete)\n",
            "windspeed: 0% (Complete)\n",
            "casual: 0% (Complete)\n",
            "registered: 0% (Complete)\n",
            "count: 0% (Complete)\n",
            "hour: 0% (Complete)\n",
            "day_of_week: 0% (Complete)\n",
            "month: 0% (Complete)\n"
          ]
        }
      ],
      "source": [
        "# Check for missing data in each column\n",
        "missing_data = df.isnull().sum()\n",
        "print(\"Missing Data Summary:\")\n",
        "print(missing_data)\n",
        "\n",
        "# Calculate percentage of missing data\n",
        "missing_percentage = (missing_data / len(df)) * 100\n",
        "print(\"\\nMissing Data Percentages:\")\n",
        "for column in df.columns:\n",
        "    if missing_data[column] > 0:\n",
        "        print(f\"{column}: {missing_percentage[column]:.1f}%\")\n",
        "    else:\n",
        "        print(f\"{column}: 0% (Complete)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d5cbf5",
      "metadata": {
        "id": "b1d5cbf5"
      },
      "source": [
        "**What this code accomplishes:**\n",
        "- `df.isnull()` creates a DataFrame of True/False values where True indicates a missing value\n",
        "- `.sum()` counts the True values (which represent missing entries) for each column - since True is treated as 1 and False as 0 in arithmetic operations\n",
        "- The percentage calculation shows the proportion of missing data relative to total records\n",
        "- The loop displays results in a business-friendly format, clearly marking complete vs incomplete columns\n",
        "- Converting to percentages helps understand the severity of missing data\n",
        "\n",
        "By running this code, we can see that there is **no missing data** in the dataset - all columns are complete. This means that **we can confidently use any column** for calculations without data quality concerns. **If we had missing data**, we would need to decide what to do with it: drop incomplete rows, exclude unreliable columns, or fill gaps using estimates (like averages or trends) - each choice would impact the quality of our analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f2e6a8",
      "metadata": {
        "id": "f8f2e6a8"
      },
      "source": [
        "### Challenge 11: Identify Missing Datetime Gaps (Skipped Hours)\n",
        "Find where the gap between consecutive `datetime` values is greater than 1 hour â€” these indicate missing hourly records in the time series. This approach works because time series data should have consistent intervals. In our case, records are generated hourly, so any gap larger than 1 hour reveals missing records in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8bc2876d",
      "metadata": {
        "id": "8bc2876d",
        "outputId": "c74a9937-8f33-422d-effa-4c38e5d3f7c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows that follow a gap > 1 hour:\n",
            "                 datetime  season  holiday  workingday  weather   temp  \\\n",
            "29    2011-01-02 06:00:00       1        0           0        3  17.22   \n",
            "49    2011-01-03 04:00:00       1        0           1        1   6.56   \n",
            "72    2011-01-04 04:00:00       1        0           1        1   5.74   \n",
            "95    2011-01-05 04:00:00       1        0           1        1   9.84   \n",
            "118   2011-01-06 04:00:00       1        0           1        2   6.56   \n",
            "...                   ...     ...      ...         ...      ...    ...   \n",
            "9063  2012-09-01 00:00:00       3        0           0        1  30.34   \n",
            "9519  2012-10-01 00:00:00       4        0           1        1  18.86   \n",
            "9975  2012-11-01 00:00:00       4        0           1        1  14.76   \n",
            "10146 2012-11-08 04:00:00       4        0           1        2  12.30   \n",
            "10430 2012-12-01 00:00:00       4        0           0        1  10.66   \n",
            "\n",
            "        atemp  humidity  windspeed  casual  registered  count  \n",
            "29     21.210        77    19.9995       0           2      2  \n",
            "49      6.820        47    26.0027       0           1      1  \n",
            "72      9.090        63     6.0032       0           2      2  \n",
            "95     11.365        48    15.0013       0           2      2  \n",
            "118     9.850        64     6.0032       0           1      1  \n",
            "...       ...       ...        ...     ...         ...    ...  \n",
            "9063   34.090        62     7.0015      22         146    168  \n",
            "9519   22.725        72     7.0015       6          39     45  \n",
            "9975   18.180        57     6.0032       8          52     60  \n",
            "10146  14.395        45    19.0012       1           9     10  \n",
            "10430  15.150        81     0.0000       9          99    108  \n",
            "\n",
            "[65 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - detect gaps > 1 hour in the datetime sequence\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df = df.sort_values(by='datetime').reset_index(drop=True)  # Fill in the time column\n",
        "\n",
        "time_diffs = df['datetime'].diff()  # Fill in the time column\n",
        "gaps = df[time_diffs > pd.Timedelta(hours=1)]  # Fill in the gap size\n",
        "\n",
        "print(\"Rows that follow a gap > 1 hour:\")\n",
        "print(gaps)  # Fill in variable name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2139fcc8",
      "metadata": {
        "id": "2139fcc8"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When detecting missing time periods, keep these practices in mind:\n",
        "- Convert the datetime column to pandas datetime format by using `pd.to_datetime()`\n",
        "- Ensure the data is sorted by time before calling `.diff()`\n",
        "- Remember that `.diff()` calculates the time difference between each row and the previous row\n",
        "- Use `pd.Timedelta(hours=1)` for a clear 1-hour threshold\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1133d85",
      "metadata": {
        "id": "c1133d85"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Your code here - detect gaps > 1 hour in the datetime sequence\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df = df.sort_values(by='datetime').reset_index(drop=True)  # Fill in the time column\n",
        "\n",
        "time_diffs = df['datetime'].diff()  # Fill in the time column\n",
        "gaps = df[time_diffs > pd.Timedelta(hours=1)]  # Fill in the gap size\n",
        "\n",
        "print(\"Rows that follow a gap > 1 hour:\")\n",
        "print(gaps)  # Fill in variable name\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02ea670",
      "metadata": {
        "id": "d02ea670"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de074d1",
      "metadata": {
        "id": "0de074d1"
      },
      "source": [
        "## Step 12: Basic Data Filtering for Business Insights\n",
        "\n",
        "Now we'll use data filtering to answer critical business questions that help optimize bike-sharing operations. By creating targeted subsets of our data, we can identify peak demand periods, understand weather impacts on ridership, and develop insights for operational planning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "685f297f",
      "metadata": {
        "id": "685f297f",
        "outputId": "6a98c61f-9782-45e7-a934-97242a3a7abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High-demand periods: 4356 out of 10886 total hours\n",
            "That's 40.0% of all hours\n",
            "\n",
            "Cold weather operations: 488 hours\n",
            "Average rentals in cold weather: 60.8\n",
            "Average rentals in warm weather: 277.2\n"
          ]
        }
      ],
      "source": [
        "# Find high-demand periods (above average usage)\n",
        "average_rentals = df['count'].mean()\n",
        "high_demand = df[df['count'] > average_rentals]\n",
        "print(f\"High-demand periods: {len(high_demand)} out of {len(df)} total hours\")\n",
        "print(f\"That's {len(high_demand)/len(df)*100:.1f}% of all hours\")\n",
        "\n",
        "# Find cold weather operations (temperature below 8Â°C)\n",
        "cold_weather = df[df['temp'] < 8]\n",
        "print(f\"\\nCold weather operations: {len(cold_weather)} hours\")\n",
        "print(f\"Average rentals in cold weather: {cold_weather['count'].mean():.1f}\")\n",
        "\n",
        "# Compare to warm weather (temperature above 26Â°C)\n",
        "warm_weather = df[df['temp'] >= 26]\n",
        "print(f\"Average rentals in warm weather: {warm_weather['count'].mean():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7026c0a4",
      "metadata": {
        "id": "7026c0a4"
      },
      "source": [
        "The analysis reveals clear patterns in bike-sharing demand:\n",
        "\n",
        "- Out of more than **10,000 recorded hours**, around **40% qualify as high-demand periods**, showing that elevated usage is a regular occurrence rather than an exception\n",
        "- **Weather plays a particularly strong role**: when temperatures drop below **8Â°C**, bike rentals average only about **61 per hour**, reflecting how cold conditions discourage riders\n",
        "- In contrast, when the temperature climbs to **26Â°C or higher**, average rentals surge to over **277 per hour**â€”more than **four times the cold-weather figure**\n",
        "\n",
        "As you can imagine, these findings have significant implications for operational planning and resource allocation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3120359e",
      "metadata": {
        "id": "3120359e"
      },
      "source": [
        "### Challenge 12: Weekend vs. Weekday Analysis\n",
        "Filter the data to compare average bike rentals on weekends (Saturday, Sunday) versus weekdays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "b6dd59a3",
      "metadata": {
        "id": "b6dd59a3",
        "outputId": "a1b90f64-60ca-4a3a-ad80-289f31523b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekend average rentals: 188.8\n",
            "Weekday average rentals: 192.7\n",
            " ABS Difference: 4.0 rentals per hour\n",
            " % Difference: 2.1% dif in rentals per hour\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Convert datetime column and extract time components\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "# Your code here - compare weekend vs weekday bike usage\n",
        "weekend_data = df[df['day_of_week'].isin(['Saturday', 'Sunday'])]  # Fill in details\n",
        "weekday_data = df[~df['day_of_week'].isin(['Saturday', 'Sunday'])] # Fill in details\n",
        "\n",
        "weekend_avg = weekend_data['count'].mean()  # Fill in column name\n",
        "weekday_avg = weekday_data['count'].mean()  # Fill in column name\n",
        "\n",
        "print(f\"Weekend average rentals: {weekend_avg:.1f}\")  # Fill in variable name\n",
        "print(f\"Weekday average rentals: {weekday_avg:.1f}\")  # Fill in variable name\n",
        "print(f\" ABS Difference: {abs(weekend_avg - weekday_avg):.1f} rentals per hour\")  # Fill in variable names\n",
        "print(f\" % Difference: {abs((weekend_avg - weekday_avg) / weekday_avg) * 100:.1f}% dif in rentals per hour\")  # Fill in variable names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeed41f6",
      "metadata": {
        "id": "aeed41f6"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
        "\n",
        "\n",
        "When comparing categorical groups like weekends vs weekdays, use these filtering strategies:\n",
        "- Use `.isin(['value1', 'value2'])` to match multiple values\n",
        "- Use `~` (tilde) for \"not\" to get the inverse: `~df['col'].isin(values)`\n",
        "- Alternative approach: `df['day_of_week'].str.contains('Saturday|Sunday')`\n",
        "- Consider statistical significance: do the groups have meaningful differences?\n",
        "- Calculate percentage difference: `((weekend_avg - weekday_avg) / weekday_avg) * 100`\n",
        "- Explore within-group variation: `weekend_data['count'].std()` vs `weekday_data['count'].std()`\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d22261d4",
      "metadata": {
        "id": "d22261d4"
      },
      "source": [
        "<details>\n",
        "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Import required libraries and load data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Washington D.C. bike-sharing dataset\n",
        "data_file_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\"\n",
        "df = pd.read_csv(data_file_path)\n",
        "\n",
        "# Convert datetime column and extract time components\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "# Your code here - compare weekend vs weekday bike usage\n",
        "weekend_data = df[df['day_of_week'].isin(['Saturday', 'Sunday'])]  # Fill in details\n",
        "weekday_data = df[~df['day_of_week'].isin(['Saturday', 'Sunday'])]  # Fill in details\n",
        "\n",
        "weekend_avg = weekend_data['count'].mean()  # Fill in column name\n",
        "weekday_avg = weekday_data['count'].mean()  # Fill in column name\n",
        "\n",
        "print(f\"Weekend average rentals: {weekend_avg:.1f}\")  # Fill in variable name\n",
        "print(f\"Weekday average rentals: {weekday_avg:.1f}\")  # Fill in variable name\n",
        "print(f\"Difference: {abs(weekend_avg - weekday_avg):.1f} rentals per hour\")  # Fill in variable names\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bda2ed",
      "metadata": {
        "id": "a7bda2ed"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b5179a4",
      "metadata": {
        "id": "8b5179a4"
      },
      "source": [
        "## Summary: Professional Pandas Data Analysis Fundamentals\n",
        "\n",
        "**What We've Accomplished**:\n",
        "- Established comprehensive pandas environment and data manipulation workflows\n",
        "- Implemented systematic data loading and exploration methodologies for real transportation data\n",
        "- Performed data quality assessment with missing data detection protocols\n",
        "- Created time-based feature extraction and business intelligence filtering frameworks\n",
        "\n",
        "**Key Technical Skills Mastered**:\n",
        "- Series and DataFrame creation with meaningful business labeling systems\n",
        "- CSV data loading and basic analysis for professional client datasets\n",
        "- Temporal data manipulation with datetime extraction and grouping operations\n",
        "- Data filtering and aggregation techniques for business insight generation\n",
        "\n",
        "**Next Steps**: Next, we'll advance to professional data cleaning techniques, mastering missing value handling, outlier identification, and data preparation protocols that ensure our transportation datasets meet the rigorous quality standards required for sophisticated predictive modeling and client-ready analysis.\n",
        "\n",
        "Your bike-sharing client now has a solid data foundation built with professional pandas techniques that demonstrate systematic data exploration and business-focused analytical thinking - the core competencies that consulting firms expect from junior transportation data analysts!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}